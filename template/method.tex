\chapter{提案手法}\label{chap:method}

\section{概要}
経験則をもとになくしものの発生原理をモデル化
手に持っていたものを置いて次の動作に遷移
置いたことを忘れる
例
郵便受けから新聞紙をとろうと手に持っていたスマートフォンを床に置いたらそのまま忘れた

モデル化
人は動作をノードとするマルコフ連鎖に従って行動
異なる動作に遷移する際, 確率的になくしもの発生
遷移を繰り返せばいつかはなくしものが発生
どの動作に遷移する際になくしものが発生しやすい？
各動作でなくしものが発生する確率

動作ごとに利用者がいる位置の傾向を表す分布を用意
なくしもの発生確率を重みとして利用者位置分布を加算
和をなくしものの位置の分布とする

利用者位置分布とマルコフ連鎖を通じてなくしものが発生していない状況下での利用者の行動を反映

\section{定式化}
捜索範囲を$ X \subseteq \mathbb{R}^d \  (d=2,3)$とおく．
マルコフ連鎖の状態数すなわち動作の数を$ n $, 各動作を$ m_i\ (i=1,2,\cdots ,n)$, 
$ t \in \{0,1,2,\cdots\} $回目の遷移の後の動作を$ M_t $とおく．ただし$ M_0 $は初期動作とする. 
$ m_i $から$ m_j $に遷移する確率$ \mathrm{P}(M_t = m_j | M_{t-1} = m_i) $を$ a_{i j} $, 
初期動作が$ m_i $である確率$ \mathrm{P}(M_0 = m_i) $を$ s_i $とおく. 
ただしマルコフ連鎖はエルゴード的であると仮定する. \cite{funaki}
また$ R_t\ (t=1,2,3,\cdots) $を$ 0 $または$ 1 $をとる確率変数とする. 
$ \mathrm{P}(R_t = 0 | M_t = m_j , M_{t - 1} = m_i) $を$ m_i $から$ m_j $への遷移失敗確率と呼ぶ. 
この確率は$ i = j $のとき$ 0 $, $ i \ne j $のとき$ M_j $にのみ依存した$ 0 $より真に大きい値をとると仮定しその値を$ \theta_j $とおく. 
\begin{equation}
    \mathrm{P}(R_t = 0 | M_t = m_j , M_{t - 1} = m_i) =
    \begin{cases}
        0        & \text{if $i = j$}\\
        \theta_j & \text{if $i \ne j$}
    \end{cases}
\end{equation}
はじめて$ R_t = 0 $となるときになくしものが発生するとし, そのような$ t $を$ \tau $とおく. 
すなわち$ \tau $は任意の$ t^{\prime} \in \{1,2,3,\cdots,t-1\} $に対し$ R_{t^{\prime}} = 0 $かつ$ R_t = 1 $を満たす$ t $である. 
$ \mathrm{P}(\tau < \infty , M_{\tau} = m_i) $を$ p_i $とおき$ m_i $におけるなくしもの発生確率と呼ぶ. 

なくしもの発生確率$ p_i $は下式で求まる. 
\begin{equation} \label{eq:p}
\V{p} = \V{L}(\V{I}-\V{K})^{-1}\V{s}
\end{equation}
ただし
\begin{align*}
\V{p} &= (p_1,p_2,\cdots,p_n)^\mathrm{T} \\
\V{L} &=
\begin{pmatrix}
    0 & \theta_1 a_{2 1} & \cdots & \theta_1 a_{n 1} \\
    \theta_2 a_{1 2} & 0 & \cdots & \theta_2 a_{n 2} \\
    \vdots & \vdots & \ddots & \vdots \\
    \theta_n a_{1 n} & \theta_n a_{2 n} & \cdots & 0 \\
\end{pmatrix}
\\
\V{I} &= n行n列の単位行列 \\
\V{K} &=
\begin{pmatrix}
    a_{1 1} & (1 - \theta_1) a_{2 1} & \cdots & (1 - \theta_1) a_{n 1} \\
    (1 - \theta_2) a_{1 2} & a_{2 2} & \cdots & (1 - \theta_2) a_{n 2} \\
    \vdots & \vdots & \ddots & \vdots \\
    (1 - \theta_n) a_{1 n} & (1 - \theta_n) a_{2 n} & \cdots & a_{n n} \\
\end{pmatrix}
\\
\V{s} &= (s_1,s_2,\cdots,s_n)^\mathrm{T}
\end{align*}
とおいた. 
導出は\ref{sect:proof_p}節にある. 

動作$ m_i $に対応する利用者の位置分布を$ b_i:X \rightarrow [0,\infty) $とし$ \int_X b_i = 1 $を満たすとする. 
利用者位置分布をなくしもの発生確率で重み付けした和$ \sum_i p_i b_i $を$ h $とおき, なくしもの位置分布と呼ぶ. 

\section{学習}
$ s_i, a_{i j}, b_i $について, これらはマルコフ連鎖と位置分布の組み合わせであり連続型HMM（Hidden Markov Model）に類似していることに注目する. 
HMMのパラメータ学習アルゴリズムにBaum-Welchアルゴリズムがある. \cite{ishii_ueda}
$ b_i $が多変量ガウス分布であるという制約の下, 利用者の位置を監視しBaum-Welchアルゴリズムを適用することで$ s_i, a_{i j}, b_i $を同時に学習する. 

$ \theta_i $の学習にはベイズ推論を用いる．
なくしものの発見場所を$ \V{x}_{\mathrm{found}} $, $ \V{\theta} = (\theta_1 , \theta_2 , \cdots , \theta_n)^\mathrm{T} $の事前分布の密度関数を$ f $とおく．
$ \V{\theta} $の分布の更新にあたり尤度としてなくしもの位置分布$ h $を用いる. 
すなわち事後分布の密度関数$ f(\V{\theta} | x_{\mathrm{found}}) $を下式で定める. 
\begin{equation} \label{eq:new_f}
    f(\V{\theta} | \V{x}_{\mathrm{found}}) \propto h(\V{x}_{\mathrm{found}} , \V{\theta}) f(\V{\theta})
\end{equation}
ただし$ h $を$ \V{x} \in X $と$ \V{\theta} $の関数とみなしている. 

\section{推定}
\begin{equation} \label{eq:exp}
    E_{\V{\theta}} [h] = \int_{0}^{1} \int_{0}^{1} \cdots \int_{0}^{1} h f(\theta) \mathrm{d}\theta_1 \mathrm{d}\theta_2 \cdots \mathrm{d}\theta_n
\end{equation}
を推定結果とする. 

ここに書いてある方法を使えば, 秒速で秒速で1億円稼ぐ男になれます. なれません. 


\section{手法の概要}

図に書くと図\ref{fig:vq_map_128part}っていう感じ. 
式で書くとだいたい以下のような感じになるんじゃないんかなー. 
式(\ref{eq:j})が肝. 

\begin{figure}[h]
        \begin{center}
        \includegraphics[width=1.0\linewidth]{figs/vq_map_128part.eps}
        \caption{Representative Vectors of the $N_c = 128$ Map}
        \label{fig:vq_map_128part}
        \end{center}
\end{figure}




\begin{align}
s_0, a(t_0), s(t_1), a(t_1), s(t_2), a(t_2), \dots, a(t_{T-1}), s_\text{f} \quad (s_0 = s(t_0), s_\text{f} = s(t_T)). 
\end{align}
\begin{align}
& s_0, \pi(s_0), s(t_1), \pi(s(t_1)), s(t_2), \pi(s(t_2)), \dots, \pi(s(t_{T-1})), s_\text{f}
\end{align}
\begin{align}
\pi &: \mathcal{S} \to \mathcal{A} \label{eq:policy_state_action_sequence}
\end{align}
\begin{align}
\mathcal{S} &= \{s_i | i=0,1,2,\dots,N-1 \}, \text{ and} \\
\mathcal{A} &= \{a_j | j=0,1,2,\dots,M-1 \}
\end{align}
\begin{align}
\pi : \mathcal{S} - \mathcal{S}_\text{f} \to \mathcal{A}. \label{eq:policy}
\end{align}
\begin{align}
\dot{\V{x}}(t) &= \V{f}[\V{x}(t),\V{u}(t)], \quad \V{x}(0) = \V{x}_0, \quad t \in [0,t_\text{f}].\label{eq:system} \\
&  \nonumber 
\end{align}
\begin{align}
g[\V{x}(t), \V{u}(t)] \in \Re \quad (t \in [0,t_\text{f}]). \label{eq:evaluation_function}
\end{align}
\begin{align}
J[\V{u}] = \int_{0}^{t_\text{f}} g[\V{x}(t), \V{u}(t)] dt + V(\V{x}_\text{f}).  \label{eq:functional}
\end{align}
\begin{align}
\max_{\V{u}:[0,t_\text{f}) \to \Re^m} J[\V{u};\V{x}_0].  \label{eq:optimal_control_problem}
\end{align}
\begin{align}
\V\pi^*: \Re^n \to \Re^m
\end{align}
\begin{align}
\max_{\V{u}:[0,t_\text{f}) \to \Re^m} J[\V{u};\V{x}_0] &= \max_{\V{u}:[0,t') \to \Re^m} \int_{0}^{t'} g[\V{x}(t), \V{u}(t)] dt \nonumber \\ &+ \max_{\V{u}:[t',t_\text{f}) \to \Re^m} \int_{t'}^{t_\text{f}} g[\V{x}(t), \V{u}(t)] dt + V(\V{x}_\text{f}) \nonumber \\
	&= \max_{\V{u}:[0,t') \to \Re^m} \int_{0}^{t'} g[\V{x}(t), \V{u}(t)] dt + \max_{\V{u}:[t',t_\text{f}) \to \Re^m} J[\V{u};\V{x}(t')]. \label{eq:j}
\end{align}
\begin{align}
V^{\V\pi}(\V{x}) &= J[\V{u};\V{x}], \label{eq:def_of_value} \\
&\text{ where } \V{u}(t) = \V\pi(\V{x}(t)), \ 0\le t \le t_\text{f}. \nonumber 
\end{align}
\begin{align}
\mathcal{P}_{ss'}^a &= P[s(t_{i+1}) = s' | s(t) = s,a(t) = a], \label{eq:state_transition}\\
&(\forall t \in \{t_0,t_1,\dots,t_{T-1}\}, \forall s \in \mathcal{S} - \mathcal{S}_\text{f}, \text{ and } \forall s' \in \mathcal{S}). \nonumber
\end{align}
\begin{align}
\mathcal{R}_{ss'}^a \in \Re
\end{align}
\begin{align}
J[a;s(t_0)] = J[a(0),a(1),\dots,a(t_{T-1})] = \sum_{i=0}^{T-1} \mathcal{R}_{s(t_i)s(t_{i+1})}^{a(t_i)} + V(s(t_T)),
\end{align}
\begin{align}
\max J[a;s(t_0)]. 
\end{align}
\begin{align}
J^{\V{\pi}} = \int_\mathcal{X} p(\V{x}_0) J[\V{u};\V{x}_0] d\V{x}_0 \quad\Big(\V{u}(t) = \V\pi(\V{x}(t))\Big),\label{eq:eval_general}
\end{align}
\begin{align}
\dfrac{\partial V(\V{x})}{\partial t} = \max_{\V{u}\in\mathcal{U}} \left[g[\V{x},\V{u}] + \dfrac{\partial V(\V{x})}{\partial\V{x}} \V{f}[\V{x},\V{u}] \right].\label{eq:hjb}
\end{align}
\begin{align}
U_\text{att}(\V{x}) = \dfrac{1}{2} \xi \rho^2 (\V{x})
\end{align}
\begin{align}
U_\text{rep}(\V{x}) =
\begin{cases}
\dfrac{1}{2}\eta \left( \dfrac{1}{\rho(\V{x})} - \dfrac{1}{\rho_0} \right)^2 &\text{if } \rho(\V{x}) \le \rho_0, \\
0 &\text{if } \rho(\V{x}) > \rho_0,
\end{cases}
\end{align}
\begin{align}
U(\V{x}) = U_\text{att}(\V{x}) + U_\text{rep}(\V{x})
\end{align}
\begin{align}
\V{F}(\V{x}) &= - (\partial U/\partial x_1,\partial U/\partial x_2,\dots,\partial U/\partial x_n)^T \nonumber \\
&= -\nabla U({\V{x}}). 
\end{align}
\begin{align}
V(\V{x};\theta_1,\theta_2,\dots,\theta_{N_\theta}) \nonumber
\end{align}
\begin{align}
\phi_i(\V{x}) &= \exp \left\{-\dfrac{1}{2}(\V{x} - \V{c}_i)^t M_i (\V{x} - \V{c}_i) \right\},
\end{align}
\begin{align}
b_i(\V{x}) &= \dfrac{\phi_i(\V{x})}{\sum_{j=1}^{N_\phi} \phi_j(\V{x})}, \ (N_\phi: \text{ number of RBFs in the space})
\end{align}
\begin{align}
V(\V{x}) &= \sum_{i=1}^{N_\phi} \nu_i b_i(\V{x}). \label{eq:rbf_weighted_sum}
\end{align}
\begin{align}
\phi_i(x) &= \exp \left\{-\dfrac{1}{2}(x - i)^2 \right\} \nonumber
\end{align}

\begin{align}
V(\V{x}) = \sum_{i=0}^3 w_i V(\V{x}_i)
\end{align}


\begin{table}[htbp]
        \begin{center}
	\caption{謎のパラメータ}
        \label{table:parameter_value}
\begin{footnotesize}
\begin{minipage}{12em}
        \begin{tabular}{c|rl}
\multicolumn{3}{c}{(a)}\\
        \thline
parameter & \multicolumn{2}{c}{value} \\
        \hline
$\ell_1,\ell_2$ & 1.0&[m] \\
$\ell_{c1},\ell_{c1}$ & 0.50&[m] \\
$m_1,m_2$ & 1.0&[kg] \\
$I_1,I_2$ & 1.0&[kg m$^2$] \\
$g$ & 9.8&[m/s$^2$] \\
   \thline
  \end{tabular}
\end{minipage}
\hspace{2em}
\begin{minipage}{12em}
        \begin{tabular}{c|l}
\multicolumn{2}{c}{(b)}\\
        \thline
variable & domain \\
        \hline
$\theta_1$ & $(-\infty,\infty)$ \\
$\theta_2$ & $(-\infty,\infty)$ \\
$\dot\theta_1$ & $[-720,720]$[deg/s] \\
$\dot\theta_2$ & $[-1620,1620]$[deg/s] \\
\hline
$\tau$ & $-1,0,$ or $1$[Nm] \\
   \thline
  \end{tabular}
\end{minipage}
\end{footnotesize}
  \end{center}
\end{table}


